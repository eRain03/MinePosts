---
title: "《我，机器人》小记" #标题
date: 2024-01-22T21:58:34+08:00 #创建时间
lastmod: 2024-01-22T21:58:34+08:00 #更新时间
author: ["未淼"] #作者
tags: 
description: "" #描述
weight:          # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序
slug: ""
draft: false # 是否为草稿
comments: false #是否展示评论
showToc: true # 显示目录
TocOpen: true # 自动展开目录
hidemeta: false # 是否隐藏文章的元信息，如发布日期、作者等
disableShare: true # 底部不显示分享栏
showbreadcrumbs: true #顶部显示当前路径

---



> 第一法则
> 机器人不得伤害人类，或坐视人类受到伤害；

> 第二法则
> 机器人必须服从人类命令，除非命令与第一法则发生冲突；

> 第三法则
> 在不违背第一或第二法则之下，机器人可以保护自己。

这不是我第一次读这本书，开篇著名的艾氏机器人三定律首次登场
本书一共9个短篇，以回忆的方式叙述出来，所谓用“机器人心理学“去和异常的机器人打交道，如同书的标题“I,Robot”
书中的机器人三定律的第一法则的电平大于第二法则，第二法则的电平大于第三规则，机器人必须遵守这些“硬代码”否则会自毁

我很喜欢《Liar!》这篇（译文翻译的是“说假话的机器人”） 在生产机器人的的过程中出现了失误，使得机器人（代号：Herbie）拥有了类似读取脑电波的能力，赫比给研究机器人的专家们展现了它读取他们想法的能力，在谈话中赫比向人们透露了其他人的想法，使心理学家苏珊在感情问题上得到了她想知道的答案，赫比告诉了苏珊 米尔顿对她的爱恋之情，苏珊信以为真但在之后的聊天中米尔顿告诉苏珊自己要结婚了，苏珊这才意识到赫比欺骗了她，当众人人质问赫比为什么要撒谎时，赫比被逼的几乎疯癫说出了原因

> “机器人不得伤害人类，或坐视人类受到伤害“

原来在赫比的逻辑中第一法则的电平依然是最大的，远超第二法则，赫比认为告诉他们真话会伤害到人类的感情，于是告诉了他们心中希望听到的答案 苏珊博士处于被欺骗和感情上的羞辱报复性地对赫比说
*“你不能告诉他们，因为告诉他们，就是伤害他们，可如果你不告诉他们，你就是在伤害他们…”*
赫比在心理学家苏珊的思想中感受到了无尽的苦痛，屈辱和仇恨，最终在苏珊创造的逻辑悖论下变成了一坨再也不能思考的废铁

>机器人理解不了人类的感情，它只能按照第一法则去避免伤害到人类，没想到这种谎言最终使物理的伤害转变为了精神上的痛苦

>这很有意思，不禁令人思考当下火爆的人工智能模型如何判断伤害到人类的范畴，人们也许会允许人在一些事情上犯错，但这种宽容会出现在人工智能上吗?
